{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2500bb76-d009-4648-8bb7-84a3db287a13",
   "metadata": {},
   "source": [
    "# Monitoring ML Training Pipeline: Preprocessing\n",
    "- load extracted raw data\n",
    "- enforce datatypes\n",
    "- engineer new features\n",
    "- split train-test\n",
    "- train transformation models for\n",
    "    - imputing missing values\n",
    "    - converting categorical to numerical values\n",
    "    - rescaling\n",
    "- apply the transformation models on both training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d036ca6c-84e2-4a69-ba01-fbd51a4769ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'dags', 'src'))\n",
    "\n",
    "import helpers\n",
    "import config\n",
    "\n",
    "reload(helpers)\n",
    "reload(config)\n",
    "\n",
    "engineered_vars = {\n",
    "    \"categorical\": [\"application_year\", \"application_month\", \"application_week\", \"application_day\", \"application_season\"],\n",
    "    \"numerical\": [\"current_credit_balance_ratio\"],\n",
    "    \"date\": [\"application_date\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57448c20-813e-40e3-b5b0-bd96fc1fded9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64ac252b-a013-450a-9937-10b9538ec4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### helpers.py methods ####\n",
    "def save_dataset(df:pd.DataFrame, path:str):\n",
    "    \"\"\"\n",
    "    Save data set.\n",
    "    :param df: DataFrame\n",
    "    :param path: str\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"[INFO] Dataset saved to {path}\")\n",
    "\n",
    "def load_dataset(path:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data set.\n",
    "    :param path: str\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def save_model_as_pickle(model, model_name, directory=None):\n",
    "    \"\"\"\n",
    "    Save a model as a pickle file.\n",
    "    :param model: AnyType\n",
    "    :param model_name: str\n",
    "    :param directory: str\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if directory:\n",
    "        filename = os.path.join(directory, model_name+\".pkl\")\n",
    "    else:\n",
    "        filename = os.path.join(config.PATH_DIR_MODELS, model_name+\".pkl\")\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(\"[INFO] Model saved as pickle file:\", filename)\n",
    "\n",
    "def load_model_from_pickle(model_name: str):\n",
    "    \"\"\"\n",
    "    Load a pickle model.\n",
    "    :param model_name: str\n",
    "    :return: AnyType\n",
    "    \"\"\"\n",
    "    with open(os.path.join(config.PATH_DIR_MODELS, model_name+\".pkl\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_model_as_json(model:dict, model_name:str, directory:str=None):\n",
    "    \"\"\"\n",
    "    Save a model as a json file.\n",
    "    :param model: dict\n",
    "    :param model_name: str\n",
    "    :param directory: str\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if directory:\n",
    "        filename = os.path.join(directory, model_name+\".json\")\n",
    "    else:\n",
    "        filename = os.path.join(config.PATH_DIR_MODELS, model_name+\".json\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(model, f)\n",
    "    print(\"[INFO] Model saved as json file:\", filename)\n",
    "\n",
    "def load_model_from_json(model_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load a json model.\n",
    "    :param model_name: str\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    with open(os.path.join(config.PATH_DIR_MODELS, model_name+\".json\"), \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d8af5ed-7bbe-441e-8158-78e1e5c1b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### preprocess.py methods #####\n",
    "\n",
    "######  missing values ######\n",
    "def get_variables_with_missing_values(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get variables with missing values.\n",
    "    :param df: DataFrame\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    missing_counts = df.isnull().sum()\n",
    "    return missing_counts[missing_counts>0].index.tolist()\n",
    "\n",
    "def impute_missing_values(df:pd.DataFrame, method:str=\"basic\", mode:str=None, cat_vars:list=config.CAT_VARS, num_vars:list=config.NUM_VARS, job_id:str=\"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Treat missing values.\n",
    "    \n",
    "    :param df: DataFrame\n",
    "    :param method: str, \"basic\" or \"advanced\"\n",
    "        For basic method\n",
    "            If the column with missing values is a categorical variable, we can impute it with the most frequent value.\n",
    "            If the column with missing values is a numerical variable, we can impute it with the mean value.\n",
    "        For advanced method\n",
    "    :param mode: str, \"training\" or \"inference\"\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    assert mode in (\"training\", \"inference\"), f\"mode must be either 'training' or 'inference', but got {mode}\"\n",
    "    assert method in [\"basic\", \"advanced\"], f\"{method} is not a valid methods (basic, advanced)\"\n",
    "    if mode==\"training\":\n",
    "        model = {\n",
    "            \"method\": method,\n",
    "            \"imputes\": dict()\n",
    "        }\n",
    "        for col in df.columns:\n",
    "            print(\"[INFO] Treating missing values in column:\", col)\n",
    "            model[\"imputes\"][col] = dict()\n",
    "            if method==\"basic\":\n",
    "                if col in set(cat_vars + engineered_vars[\"categorical\"]):\n",
    "                    model[\"imputes\"][col]['mode'] = df[df[col].notnull()][col].mode()[0]\n",
    "                elif col in set(num_vars + engineered_vars[\"numerical\"]):\n",
    "                    model[\"imputes\"][col]['mean'] = df[df[col].notnull()][col].mean()\n",
    "                elif col in set(config.DATETIME_VARS + engineered_vars[\"date\"]):\n",
    "                    model[\"imputes\"][col]['mode'] = df[df[col].notnull()][col].mode()[0]\n",
    "                elif col in [\"loan_id\", \"customer_id\", \"loan_status\"] + config.EXC_VARIABLES:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f\"[ERROR]{col} is not a valid variable\")\n",
    "            if method==\"advanced\":\n",
    "                raise(NotImplementedError)\n",
    "        helpers.save_model_as_pickle(model, f\"{job_id}_missing_values_model\")\n",
    "        return impute_missing_values(df, method=method, mode=\"inference\", cat_vars=cat_vars, num_vars=num_vars, job_id=job_id)\n",
    "    else:\n",
    "        model = helpers.load_model_from_pickle(model_name=f\"{job_id}_missing_values_model\")\n",
    "        cols = get_variables_with_missing_values(df)\n",
    "        method = model[\"method\"]\n",
    "        if method==\"basic\":\n",
    "            for col in cols:\n",
    "                if col in set(cat_vars + engineered_vars[\"categorical\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mode'], inplace=True)\n",
    "                elif col in set(num_vars + engineered_vars[\"numerical\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mean'], inplace=True)\n",
    "                elif col in set(config.DATETIME_VARS + engineered_vars[\"date\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mode'], inplace=True)\n",
    "                elif col in [\"loan_id\", \"customer_id\", \"loan_status\"] + config.EXC_VARIABLES:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f\"[ERROR]{col} is not a valid variable. Pre-trained vairables: {list(model['imputes'].keys())}\")\n",
    "        if method==\"advanced\":\n",
    "            raise(NotImplementedError)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "495d6324-d93f-4b19-b85a-a920383166b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### enforcing datatypes ######\n",
    "def enforce_datatypes_on_variables(df:pd.DataFrame, cat_vars:list=[], num_vars:list=[]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform variables.\n",
    "    :param df: DataFrame\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"application_time\"] = pd.to_datetime(df[\"application_time\"])\n",
    "    for var in num_vars:\n",
    "        df[var] = df[var].apply(lambda x: enforce_numeric_to_float(x))\n",
    "    for var in cat_vars:\n",
    "        df[var] = df[var].astype(str)\n",
    "    return df\n",
    "\n",
    "def enforce_numeric_to_float(x: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert numeric to float. To ensure that all stringified numbers are converted to float.\n",
    "    :param x: str\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(re.sub(\"[^0-9.]\",\"\", str(x)))\n",
    "    except ValueError:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a71b3527-8eb7-4796-833e-97f9c1c3762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### encoding categorical variables ######\n",
    "def categorize_years_in_current_job(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Categorize years in current job.\n",
    "    :param x: str\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    x = str(x).strip()\n",
    "    if x=='< 1 year':\n",
    "        return 0\n",
    "    if x in ('1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10 years'):\n",
    "        return int(re.sub(\"[^0-9]\", \"\", x))\n",
    "    if x=='10+ years':\n",
    "        return 11\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def term_to_int(x:str) -> int:\n",
    "    \"\"\"\n",
    "    Convert term to int.\n",
    "    :param x: str, lower cased term\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    if x==\"short term\":\n",
    "        return 0\n",
    "    elif x==\"long term\":\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def home_ownership_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert home ownership to int.\n",
    "    :param x: str, lower cased home ownership\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    if x==\"rent\":\n",
    "        return 0\n",
    "    elif \"mortgage\" in x:\n",
    "        return 1\n",
    "    elif \"own\" in x:\n",
    "        return 2\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def train_purpose_to_int_model(x:pd.Series, method:str, job_id:str=\"\") -> dict:\n",
    "    \"\"\"\n",
    "    build a model file to be used to convert string variable `purpose` into integer datatype\n",
    "    :param x:pd.Series\n",
    "    :param method: str, \"ranking\", \"weighted ranking\", \"relative ranking\"\n",
    "        - ranking\n",
    "            rank values by their sorted frequency and assign a rank to each value. The most frequent value will have the highest rank\n",
    "        - relative ranking \n",
    "            replace each value by the ratio of its frequency to the highest frequency\n",
    "        - weighted ranking\n",
    "            replace each value by the ratio of its frequency to the total number of values (or sum of frequencies)\n",
    "    :param job_id: str, job id\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    assert method in [\"ranking\", \"weighted ranking\", \"relative ranking\"], f\"{method} is not a valid methods (ranking, weighted ranking, relative ranking)\"\n",
    "    val_counts = x.value_counts()\n",
    "    if method==\"ranking\":\n",
    "        uniq_vals = sorted(val_counts.unique(), reverse=False)\n",
    "        val_to_int = dict(zip(uniq_vals, range(1, len(uniq_vals)+1)))\n",
    "        model = val_counts.apply(lambda x: val_to_int[x]).to_dict()\n",
    "        helpers.save_model_as_json(model, f\"{job_id}_purpose_to_int_model\")        \n",
    "        return model\n",
    "    if method==\"relative ranking\":\n",
    "        model = (val_counts/val_counts.max()).to_dict()\n",
    "        helpers.save_model_as_json(model, f\"{job_id}_purpose_to_int_model\")        \n",
    "        return model\n",
    "    if method==\"weighted ranking\":\n",
    "        model = (val_counts/val_counts.sum()).to_dict()\n",
    "        helpers.save_model_as_json(model, f\"{job_id}_purpose_to_int_model\")        \n",
    "        return model\n",
    "\n",
    "\n",
    "def purpose_to_int(x:pd.Series, mode:str, method:str=None, model:str=None, job_id:str=\"\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert purpose to int.\n",
    "    :param x:pd.Series\n",
    "    :param mode: str, choose from \"training\", \"inference\"\n",
    "    :param method: str, \"ranking\",  \"weighted ranking\", \"relative ranking\"\n",
    "        - ranking \n",
    "            rank values by their frequency and assign a rank to each value. The most frequent value will have the highest rank\n",
    "        - relative ranking\n",
    "            replace each value by the ratio of its frequency to the highest frequency\n",
    "        - weighted ranking\n",
    "            replace each value by the ratio of its frequency to the total number of values\n",
    "        when method is None and model is not None, any new value (not present in the model) will be encoded as 0\n",
    "    :param model: method, model to predict the purpose. If None, a new model will be trained and saved to the default directory of models as defined in the config file\n",
    "    :param save_report: bool, whether to save the report of missed/new values. Not implemented for nor\n",
    "    :param job_id: str, job id\n",
    "    :return:pd.Series\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Converting purpose to int using method:\", method)\n",
    "    if model==None:\n",
    "        print(\"[INFO] No model for purpose-to-int conversion provided. Training a new model first...\")\n",
    "        mode = \"training\"\n",
    "    if mode==\"training\":\n",
    "        model = train_purpose_to_int_model(x, method, job_id=job_id)\n",
    "        # return purpose_to_int(x, method=method, model=model, job_id=job_id)\n",
    "        return x.apply(lambda x: model.get(x, 0))\n",
    "    else:\n",
    "        model = helpers.load_model_from_json(model_name=f\"{job_id}_purpose_to_int_model\")\n",
    "        return x.apply(lambda x: model.get(x, 0))\n",
    "\n",
    "def loan_status_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert loan status to int.\n",
    "    :param x: str, lower cased loan status\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "\n",
    "    assert x in (\"loan given\", \"loan refused\") or isinstance(x, int), f\"{x} is not a valid loan status and is not an integer\"\n",
    "    if x.strip()==\"loan refused\":\n",
    "        return 0\n",
    "    if x.strip()==\"loan given\":\n",
    "        return 1\n",
    "    return x\n",
    "\n",
    "def encode_categorical_variables(df:pd.DataFrame, mode=\"training\", purpose_encode_method=\"ranking\", job_id:str=\"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode categorical variables.\n",
    "    :param df: DataFrame\n",
    "    :param mode: str, \"training\" or \"inference\"\n",
    "    :param purpose_encode_method: str, choose from \"ranking\", \"weighted ranking\", \"relative ranking\"\n",
    "    :param job_id: str, job id\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    assert mode in (\"training\", \"inference\"), f\"{mode} is not a valid mode (training , inference)\"\n",
    "    assert isinstance(job_id, str)\n",
    "    for col in config.CAT_VARS:\n",
    "        assert col in df.columns, f\"{col} not in {df.columns}\"\n",
    "        df[col] = df[col].str.lower()\n",
    "\n",
    "    df[\"term\"] = df[\"term\"].apply(lambda x: term_to_int(x))\n",
    "    df[\"home_ownership\"] = df[\"home_ownership\"].apply(lambda x: home_ownership_to_int(x))  \n",
    "    df[\"years_in_current_job\"] = df[\"years_in_current_job\"].apply(lambda x: categorize_years_in_current_job(x))\n",
    "    if config.TARGET.lower() in df.columns:\n",
    "        df[config.TARGET.lower()] = df[config.TARGET.lower()].apply(lambda x: loan_status_to_int(x))\n",
    "    df[\"purpose\"] = purpose_to_int(df[\"purpose\"], mode=mode, method=purpose_encode_method, job_id=job_id)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66396d4a-c68e-447a-b125-df974fd6b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### engineer new variables ######\n",
    "def engineer_variables(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Engineer variables.\n",
    "    :param df: DataFrame\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    for col in [\"application_time\"]:\n",
    "        assert col in df.columns, f\"{col} not in {df.columns}\"\n",
    "\n",
    "    df[\"application_date\"] = df[\"application_time\"].dt.date\n",
    "    df[\"application_year\"] = df[\"application_time\"].dt.year\n",
    "    df[\"application_month\"] = df[\"application_time\"].dt.month\n",
    "    df[\"application_week\"] = df[\"application_time\"].dt.week\n",
    "    df[\"application_day\"] = df[\"application_time\"].dt.day\n",
    "    df[\"application_season\"] = df[\"application_month\"].apply(lambda x: month_to_season(x))\n",
    "    df[\"current_credit_balance_ratio\"] = (df[\"current_credit_balance\"]/df[\"current_loan_amount\"]).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "def month_to_season(month:int) -> int:\n",
    "    \"\"\"\n",
    "    Convert date to season.\n",
    "    :param m: int, month between 1 and 12\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    if month in [1, 2, 3]:\n",
    "        return 1\n",
    "    elif month in [4, 5, 6]:\n",
    "        return 2\n",
    "    elif month in [7, 8, 9]:\n",
    "        return 3\n",
    "    elif month in [10, 11, 12]:\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a800973c-51d4-4f63-ab48-901ceb32741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data transformation ####\n",
    "def rescale_data(df:pd.DataFrame, method:str='standardize', mode:str='training', columns:list=[], job_id:str=\"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rescale data.\n",
    "    :param df: DataFrame\n",
    "    :param method: str, 'standardize' or 'minmax'\n",
    "    :param mode: str, 'training' or 'inference'\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    assert method in ('standardize', 'minmax'), f\"{method} is not a valid method (standardize, minmax)\"\n",
    "    assert mode in ('training', 'inference'), f\"{mode} is not a valid mode (training, inference)\"\n",
    "    for col in columns:\n",
    "        assert col in df.columns\n",
    "\n",
    "    if mode=='training':\n",
    "        if method=='standardize':\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df[columns])\n",
    "        if method=='minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(df[columns])\n",
    "        model = {\n",
    "            'scaler': scaler,\n",
    "            'method': method,\n",
    "        }\n",
    "\n",
    "        helpers.save_model_as_pickle(model, f\"{config.PATH_DIR_MODELS}/{job_id}_numerical_scaler.pkl\")\n",
    "        df[list(map(lambda x: f\"{method}_{x}\", columns))] = scaler.transform(df[columns])\n",
    "        return df\n",
    "    if mode=='inference':\n",
    "        model = helpers.load_model_from_pickle(model_name=f\"{job_id}_numerical_scaler.pkl\")\n",
    "        scaler = model['scaler']\n",
    "        method = model['method']\n",
    "        for col in columns:\n",
    "            try:\n",
    "                df[col].astype(float)\n",
    "            except:\n",
    "                print(\"[DEBUG] Column skipped:\", col)\n",
    "        df[list(map(lambda x: f\"{method}_{x}\", columns))] = scaler.transform(df[columns])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63abd0a6-9a34-4ffb-bf89-47fe5062dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Preprocess ######\n",
    "def split_train_test(df:pd.DataFrame, test_size:float, method:str='time based'):\n",
    "    \"\"\"\n",
    "    Split data into train and test.\n",
    "    :param df: DataFrame\n",
    "    :param test_size: float, between 0 and 0.99\n",
    "    :param method: str, 'time based' or 'random'\n",
    "    :return: (DataFrame, DataFrame)\n",
    "    \"\"\"\n",
    "    if method=='random':\n",
    "        return df.sample(frac=1, random_state=config.RANDOM_STATE).iloc[:int(len(df)*test_size)], df.sample(frac=1, random_state=config.RANDOM_STATE).iloc[int(len(df)*test_size):]\n",
    "    if method=='time based':\n",
    "        unique_dates = sorted(df[\"application_date\"].unique())\n",
    "        \n",
    "        train_dates = unique_dates[:int(len(unique_dates)*(1-test_size))]\n",
    "        test_dates = unique_dates[unique_dates.index(train_dates[-1])+1:]\n",
    "        train_df = df[df[\"application_date\"].isin(train_dates)]\n",
    "        test_df = df[df[\"application_date\"].isin(test_dates)]\n",
    "\n",
    "        return train_df, test_df\n",
    "    raise(ValueError(f\"{method} is not a valid method (time based, random)\"))\n",
    "\n",
    "def preprocess_data(df:pd.DataFrame, mode:str, job_id:str=None, rescale=False, ref_job_id:str=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pre-process data and save preprocessed datasets for later use.\n",
    "    :param df: DataFrame\n",
    "    :param mode: str, 'training' or 'inference'\n",
    "    :param job_id: str, job_id for the preprocessed dataset\n",
    "    :param rescale: bool, whether to rescale data.\n",
    "    :param ref_job_id: str, job_id of the last deployed model. Usefull when doing inference.\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    assert mode in ('training', 'inference')\n",
    "    \n",
    "    if mode=='training':\n",
    "        assert config.TARGET in df.columns, f\"{config.TARGET} not in {df.columns}\"\n",
    "\n",
    "    df.columns = list(map(str.lower, df.columns))\n",
    "    initial_size = df.shape[0]\n",
    "    df = df[df[\"customer_id\"].notnull() & df[\"loan_id\"].notnull() & df[\"loan_status\"].notnull()]\n",
    "    if mode=='training':\n",
    "        df[\"loan_status\"] = df[\"loan_status\"].str.lower()\n",
    "    if df.shape[0] != initial_size:\n",
    "        print(f\"[WARNING] Dropped {initial_size - df.shape[0]} rows with null values in (customer_id, loan_id, loan_status)\")\n",
    "    \n",
    "    df = enforce_datatypes_on_variables(df, cat_vars=config.CAT_VARS, num_vars=config.NUM_VARS)\n",
    "    \n",
    "    df = engineer_variables(df)\n",
    "    \n",
    "    if mode=='training':\n",
    "        # split train and test data before encoding categorical variables and imputing missing values\n",
    "        train_df, test_df = split_train_test(df, config.TEST_SPLIT_SIZE, method=config.SPLIT_METHOD)\n",
    "        train_df = encode_categorical_variables(train_df, mode=\"training\", purpose_encode_method=config.PURPOSE_ENCODING_METHOD, job_id=job_id)\n",
    "        train_df = impute_missing_values(train_df, method=\"basic\", mode=\"training\", job_id=job_id)\n",
    "        if rescale:\n",
    "            train_df = rescale_data(train_df, method=config.RESCALE_METHOD, mode=\"training\", columns=num_vars + engineered_vars[\"numerical\"])\n",
    "        helpers.save_dataset(train_df, os.path.join(config.PATH_DIR_DATA, \"preprocessed\", f\"{job_id}_training.csv\"))\n",
    "        preprocess_data(test_df, mode=\"inference\", job_id=job_id, ref_job_id=job_id)\n",
    "    else:\n",
    "        # if mode is infer, no need to split train and test data\n",
    "        test_df = encode_categorical_variables(df, mode=\"inference\", purpose_encode_method=config.PURPOSE_ENCODING_METHOD, job_id=ref_job_id)\n",
    "        test_df = impute_missing_values(test_df, method=\"basic\", mode=\"inference\", job_id=ref_job_id)\n",
    "        if rescale:\n",
    "            test_df = rescale_data(test_df, method=config.RESCALE_METHOD, mode=\"inference\", columns=num_vars + engineered_vars[\"numerical\"])\n",
    "        helpers.save_dataset(test_df, os.path.join(config.PATH_DIR_DATA, \"preprocessed\", f\"{job_id}_inference.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c19e730-1c5b-4cc5-9353-f13f6253cf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f9a3f84c1aa4>:14: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"application_week\"] = df[\"application_time\"].dt.week\n",
      "<ipython-input-21-9a9da3f58eb2>:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].str.lower()\n",
      "<ipython-input-21-9a9da3f58eb2>:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"term\"] = df[\"term\"].apply(lambda x: term_to_int(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"home_ownership\"] = df[\"home_ownership\"].apply(lambda x: home_ownership_to_int(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"years_in_current_job\"] = df[\"years_in_current_job\"].apply(lambda x: categorize_years_in_current_job(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[config.TARGET.lower()] = df[config.TARGET.lower()].apply(lambda x: loan_status_to_int(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"purpose\"] = purpose_to_int(df[\"purpose\"], mode=mode, method=purpose_encode_method, job_id=job_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting purpose to int using method: weighted ranking\n",
      "[INFO] No model for purpose-to-int conversion provided. Training a new model first...\n",
      "[INFO] Model saved as json file: ../dags/models\\aa4c3eaadb02409281b589829e3c9370_purpose_to_int_model.json\n",
      "[INFO] Treating missing values in column: loan_id\n",
      "[INFO] Treating missing values in column: customer_id\n",
      "[INFO] Treating missing values in column: loan_status\n",
      "[INFO] Treating missing values in column: application_time\n",
      "[INFO] Treating missing values in column: current_loan_amount\n",
      "[INFO] Treating missing values in column: term\n",
      "[INFO] Treating missing values in column: tax_liens\n",
      "[INFO] Treating missing values in column: purpose\n",
      "[INFO] Treating missing values in column: no_of_properties\n",
      "[INFO] Treating missing values in column: home_ownership\n",
      "[INFO] Treating missing values in column: annual_income\n",
      "[INFO] Treating missing values in column: years_in_current_job\n",
      "[INFO] Treating missing values in column: months_since_last_delinquent\n",
      "[INFO] Treating missing values in column: no_of_cars\n",
      "[INFO] Treating missing values in column: no_of_children\n",
      "[INFO] Treating missing values in column: credit_score\n",
      "[INFO] Treating missing values in column: monthly_debt\n",
      "[INFO] Treating missing values in column: years_of_credit_history\n",
      "[INFO] Treating missing values in column: no_of_open_accounts\n",
      "[INFO] Treating missing values in column: no_of_credit_problems\n",
      "[INFO] Treating missing values in column: current_credit_balance\n",
      "[INFO] Treating missing values in column: max_open_credit\n",
      "[INFO] Treating missing values in column: bankruptcies\n",
      "[INFO] Treating missing values in column: application_date\n",
      "[INFO] Treating missing values in column: application_year\n",
      "[INFO] Treating missing values in column: application_month\n",
      "[INFO] Treating missing values in column: application_week\n",
      "[INFO] Treating missing values in column: application_day\n",
      "[INFO] Treating missing values in column: application_season\n",
      "[INFO] Treating missing values in column: current_credit_balance_ratio\n",
      "[INFO] Model saved as pickle file: ../dags/models\\aa4c3eaadb02409281b589829e3c9370_missing_values_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhaga\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset saved to ../dags/data\\preprocessed\\aa4c3eaadb02409281b589829e3c9370_training.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f9a3f84c1aa4>:14: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"application_week\"] = df[\"application_time\"].dt.week\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting purpose to int using method: weighted ranking\n",
      "[INFO] No model for purpose-to-int conversion provided. Training a new model first...\n",
      "[INFO] Model saved as json file: ../dags/models\\aa4c3eaadb02409281b589829e3c9370_purpose_to_int_model.json\n",
      "[INFO] Dataset saved to ../dags/data\\preprocessed\\aa4c3eaadb02409281b589829e3c9370_inference.csv\n"
     ]
    }
   ],
   "source": [
    "#change this filename and job id accordingly\n",
    "filename = \"../dags/data/raw/12196ecaa65e4831987aee4bfced5f60_2015-01-01_2015-05-31.csv\"\n",
    "job_id = \"12196ecaa65e4831987aee4bfced5f60\"\n",
    "df = helpers.load_dataset(os.path.join(filename))\n",
    "_ = preprocess_data(df=df, mode=\"training\", job_id=job_id, rescale=False, ref_job_id=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da6532ac-b039-4f4f-b8ad-c113dcdb38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.read_csv(\"../dags/data/preprocessed/12196ecaa65e4831987aee4bfced5f60_training.csv\")\n",
    "vdf = pd.read_csv(\"../dags/data/preprocessed/12196ecaa65e4831987aee4bfced5f60_inference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "081a8373-5cab-423a-bbd3-6b138149e3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>current_loan_amount</th>\n",
       "      <td>33231.000000</td>\n",
       "      <td>15612.000000</td>\n",
       "      <td>7959.000000</td>\n",
       "      <td>29346.000000</td>\n",
       "      <td>6011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_score</th>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_in_current_job</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0.786098</td>\n",
       "      <td>0.060076</td>\n",
       "      <td>0.060076</td>\n",
       "      <td>0.786098</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_debt</th>\n",
       "      <td>941.224573</td>\n",
       "      <td>941.224573</td>\n",
       "      <td>949.300000</td>\n",
       "      <td>941.224573</td>\n",
       "      <td>941.224573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_of_credit_history</th>\n",
       "      <td>18.560949</td>\n",
       "      <td>18.560949</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.560949</td>\n",
       "      <td>18.560949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months_since_last_delinquent</th>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_open_accounts</th>\n",
       "      <td>11.028741</td>\n",
       "      <td>11.028741</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.028741</td>\n",
       "      <td>11.028741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_credit_problems</th>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.145312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_credit_balance</th>\n",
       "      <td>15439.198372</td>\n",
       "      <td>15439.198372</td>\n",
       "      <td>4993.000000</td>\n",
       "      <td>15439.198372</td>\n",
       "      <td>15439.198372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_open_credit</th>\n",
       "      <td>40776.357186</td>\n",
       "      <td>40776.357186</td>\n",
       "      <td>14729.000000</td>\n",
       "      <td>40776.357186</td>\n",
       "      <td>40776.357186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankruptcies</th>\n",
       "      <td>0.105735</td>\n",
       "      <td>0.105735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105735</td>\n",
       "      <td>0.105735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax_liens</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_properties</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_cars</th>\n",
       "      <td>2.490606</td>\n",
       "      <td>2.490606</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.490606</td>\n",
       "      <td>2.490606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_children</th>\n",
       "      <td>1.501658</td>\n",
       "      <td>1.501658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.501658</td>\n",
       "      <td>1.501658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_year</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_month</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_week</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_day</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_season</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_credit_balance_ratio</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0             1             2  \\\n",
       "current_loan_amount           33231.000000  15612.000000   7959.000000   \n",
       "term                              0.000000      1.000000      0.000000   \n",
       "credit_score                   1350.696132   1350.696132   1350.696132   \n",
       "years_in_current_job             -1.000000     -1.000000      2.000000   \n",
       "home_ownership                    1.000000      1.000000      1.000000   \n",
       "annual_income                 71612.920399  71612.920399  71612.920399   \n",
       "purpose                           0.786098      0.060076      0.060076   \n",
       "monthly_debt                    941.224573    941.224573    949.300000   \n",
       "years_of_credit_history          18.560949     18.560949     21.000000   \n",
       "months_since_last_delinquent     34.752726     34.752726     34.752726   \n",
       "no_of_open_accounts              11.028741     11.028741     12.000000   \n",
       "no_of_credit_problems             0.145312      0.145312      1.000000   \n",
       "current_credit_balance        15439.198372  15439.198372   4993.000000   \n",
       "max_open_credit               40776.357186  40776.357186  14729.000000   \n",
       "bankruptcies                      0.105735      0.105735      1.000000   \n",
       "tax_liens                         0.000000      0.000000      0.000000   \n",
       "no_of_properties                  1.000000      2.000000      2.000000   \n",
       "no_of_cars                        2.490606      2.490606      4.000000   \n",
       "no_of_children                    1.501658      1.501658      0.000000   \n",
       "application_year               2015.000000   2015.000000   2015.000000   \n",
       "application_month                 1.000000      4.000000      2.000000   \n",
       "application_week                  2.000000     15.000000      7.000000   \n",
       "application_day                   6.000000      8.000000     10.000000   \n",
       "application_season                1.000000      2.000000      1.000000   \n",
       "current_credit_balance_ratio      0.000000      0.000000      0.627340   \n",
       "loan_status                       1.000000      1.000000      0.000000   \n",
       "\n",
       "                                         3             4  \n",
       "current_loan_amount           29346.000000   6011.000000  \n",
       "term                              1.000000      0.000000  \n",
       "credit_score                   1350.696132   1350.696132  \n",
       "years_in_current_job             -1.000000     -1.000000  \n",
       "home_ownership                    1.000000      1.000000  \n",
       "annual_income                 71612.920399  71612.920399  \n",
       "purpose                           0.786098      0.003407  \n",
       "monthly_debt                    941.224573    941.224573  \n",
       "years_of_credit_history          18.560949     18.560949  \n",
       "months_since_last_delinquent     34.752726     34.752726  \n",
       "no_of_open_accounts              11.028741     11.028741  \n",
       "no_of_credit_problems             0.145312      0.145312  \n",
       "current_credit_balance        15439.198372  15439.198372  \n",
       "max_open_credit               40776.357186  40776.357186  \n",
       "bankruptcies                      0.105735      0.105735  \n",
       "tax_liens                         0.000000      0.000000  \n",
       "no_of_properties                  2.000000      4.000000  \n",
       "no_of_cars                        2.490606      2.490606  \n",
       "no_of_children                    1.501658      1.501658  \n",
       "application_year               2015.000000   2015.000000  \n",
       "application_month                 2.000000      4.000000  \n",
       "application_week                  7.000000     16.000000  \n",
       "application_day                  10.000000     15.000000  \n",
       "application_season                1.000000      2.000000  \n",
       "current_credit_balance_ratio      0.000000      0.000000  \n",
       "loan_status                       1.000000      1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf[config.PREDICTORS + [config.TARGET]].head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609db493-9095-44ed-afc7-996ca59bf94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('Anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9054e5812adb29eebbcd6b680e8ef1afc4fe6e00a75ff130e735bd95b5b32301"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
